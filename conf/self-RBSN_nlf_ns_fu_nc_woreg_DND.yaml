
model: 
  type: RBSN_fusion
  kwargs:
    nlf_net: True
    real: True
    pd: 4
    eval_mu: False
    noise_correction: True

model_input: [masked] # e.g.) real_noisy, syn_noisy, masked, clean

trainer: Trainer

training:
  dataset: prep_DND
  add_noise: None # e.g.) None bypass uni-15. gau-15. gau_blind-10.:50. het_gau-10.:50. see more detail in denoise_dataset.py
  mask: bypass # e.g.) None bypass stf_0.7-rnd
  crop_size: [96, 96]
  aug: ['hflip', 'rot']
  normalization: False
  n_repeat: 2
  
  batch_size: 32

  max_epoch: 32
  
  init_lr: 3e-4
  scheduler:
    type: step
    step:
      step_size: 8
      gamma: 0.464
  loss: 1*self_L1 + 1*self_Gau_likelihood
  tmp_info: n_var, mu_singular
  optimizer:
    type: Adam
    SGD:
      momentum: 0.9
      weight_decay: 1e-4
    Adam:
      betas: [0.9, 0.999]

  warmup: False
  warmup_iter: 200

validation:
  dataset: prep_DND
  crop_size: None # [64, 64]
  add_noise: None # e.g.) None uni-15. gau-15. gau_blind-10.:50. poi_gau-10.:50.
  mask: bypass # e.g.) None bypass stf_64-rnd
  normalization: False
  multiple_cliping: 4
  n_data: 64

  val: True
  save_image: True
  
  start_epoch: 1
  interval_epoch: 1
  
checkpoint:
  save: True
  start_epoch: 1
  interval_epoch: 1

log:
  interval_iter: 10

test:
  dataset: DND_benchmark
  crop_size: None # [64, 64]
  add_noise: None # e.g.) None uni-15. gau-15. gau_blind-10.:50. poi_gau-10.:50.
  mask: bypass # e.g.) None bypass stf_64-rnd
  normalization: False
  multiple_cliping: 4

  save_image: True
