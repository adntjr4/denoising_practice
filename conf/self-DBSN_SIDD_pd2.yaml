
model: 
  type: DBSN_Likelihood
  kwargs:
    in_ch: 3
    nlf_scalar: True
    est_net: CNNest3

model_input: [masked] # e.g.) real_noisy, syn_noisy, masked, clean

trainer: Trainer

training:
  dataset: prep_SIDD
  add_noise: None # e.g.) None bypass uni-15. gau-15. gau_blind-10.:50. het_gau-10.:50. see more detail in denoise_dataset.py
  mask: bypass # e.g.) None bypass stf_0.7-rnd
  crop_size: [96, 96]
  aug: ['hflip', 'rot']
  normalization: False
  n_repeat: 1
  pd: 2
  
  batch_size: 16

  max_epoch: 32
  
  init_lr: 1e-4
  scheduler:
    type: step
    step:
      step_size: 8
      gamma: 0.32
  loss: 1.*self_Gau_likelihood
  optimizer:
    type: Adam
    SGD:
      momentum: 0.9
      weight_decay: 1e-4
    Adam:
      betas: [0.9, 0.999]

  warmup: True
  warmup_iter: 200

validation:
  dataset: SIDD_val
  crop_size: None # [64, 64]
  add_noise: None # e.g.) None uni-15. gau-15. gau_blind-10.:50. poi_gau-10.:50.
  mask: bypass # e.g.) None bypass stf_64-rnd
  normalization: False
  multiple_cliping: 2
  n_data: 256

  val: True
  save_image: True
  
  start_epoch: 1
  interval_epoch: 1
  
checkpoint:
  save: True
  start_epoch: 10
  interval_epoch: 10

log:
  interval_iter: 10

test:
  dataset: SIDD_val
  crop_size: None # [64, 64]
  add_noise: None # e.g.) None uni-15. gau-15. gau_blind-10.:50. poi_gau-10.:50.
  mask: bypass # e.g.) None bypass stf_64-rnd
  normalization: False
  multiple_cliping: 2

  save_image: True
